{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "import rdkit as rd\n",
    "from rdkit import DataStructs\n",
    "from rdkit.Chem import AllChem\n",
    "\n",
    "import sklearn as sk\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import joblib\n",
    "import shutil\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "writer = SummaryWriter('tensorboard/')\n",
    "\n",
    "random_seed = 0\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)\n",
    "torch.backends.cudnn.enabled=False\n",
    "torch.backends.cudnn.deterministic=True\n",
    "\n",
    "morgan_bits = 4096\n",
    "morgan_radius = 2\n",
    "train_epoch = 10\n",
    "batch = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "clintox_task = ['CT_TOX']\n",
    "tox21_tasks = ['NR-AR', 'NR-Aromatase', 'NR-PPAR-gamma', 'SR-HSE', \n",
    "               'NR-AR-LBD', 'NR-ER', 'SR-ARE', 'SR-MMP',\n",
    "               'NR-AhR', 'NR-ER-LBD', 'SR-ATAD5', 'SR-p53']\n",
    "\n",
    "all_tasks = tox21_tasks + clintox_task "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"./data/toxicity/datasets/tox21/split_data/seed_124/\"\n",
    "train_data=torch.load(data_path + 'train_data_tox21.pth')\n",
    "test_data=torch.load(data_path + 'test_data_tox21.pth')\n",
    "valid_data=torch.load(data_path + 'valid_data_tox21.pth')\n",
    "\n",
    "clintox_data_path = \"./data/toxicity/datasets/clintox/split_data/seed_124/\"\n",
    "train_data_clintox=torch.load(clintox_data_path + 'train_data_clintox.pth')\n",
    "test_data_clintox=torch.load(clintox_data_path + 'test_data_clintox.pth')\n",
    "valid_data_clintox=torch.load(clintox_data_path + 'valid_data_clintox.pth')\n",
    "\n",
    "train_data = train_data.merge(train_data_clintox, how='outer', on='smiles')\n",
    "test_data  = test_data.merge(test_data_clintox, how='outer', on='smiles')\n",
    "valid_data  = valid_data.merge(valid_data_clintox, how='outer', on='smiles')\n",
    "\n",
    "\n",
    "data = [train_data, test_data, valid_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles_embed = torch.load(\"./data/toxicity/smiles_embedding/smiles_embed_pretrain.pt\")\n",
    "for i in range(len(data)):\n",
    "    data[i]['smiles_embed'] = data[i]['smiles'].apply(lambda x: smiles_embed.get(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0] = data[0].fillna(-1)\n",
    "data[1] = data[1].fillna(-1)\n",
    "data[2] = data[2].fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data[0]\n",
    "test_data  = data[1]\n",
    "valid_data = data[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = []\n",
    "for tensor in train_data['smiles_embed']:\n",
    "    x_train.append(tensor)\n",
    "\n",
    "x_train = torch.stack(x_train)\n",
    "x_train = x_train.numpy()\n",
    "\n",
    "y_train = train_data[all_tasks].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = []\n",
    "\n",
    "for tensor in test_data['smiles_embed']:\n",
    "    x_test.append(tensor)\n",
    "x_test = torch.stack(x_test)\n",
    "x_test = x_test.numpy()\n",
    "\n",
    "y_test = test_data[all_tasks].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_valid = []\n",
    "for tensor in valid_data['smiles_embed']:\n",
    "    x_valid.append(tensor)\n",
    "x_valid = torch.stack(x_valid)\n",
    "x_valid = x_valid.numpy()\n",
    "\n",
    "    \n",
    "y_valid = valid_data[all_tasks].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_train = np.sum(y_train >= 0, 0)\n",
    "N_test  = np.sum(y_test >= 0, 0)\n",
    "N_valid  = np.sum(y_valid >= 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert data for pytorch\n",
    "x_train_torch = x_train.astype(np.float32)\n",
    "y_train_torch = y_train.astype(np.float32)\n",
    "\n",
    "x_test_torch = x_test.astype(np.float32)\n",
    "y_test_torch = y_test.astype(np.float32)\n",
    "\n",
    "x_valid_torch = x_valid.astype(np.float32)\n",
    "y_valid_torch = y_valid.astype(np.float32)\n",
    "\n",
    "input_shape = x_train_torch.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class for MTDNN data\n",
    "class MTDNNData(Dataset):\n",
    "\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = MTDNNData(x_train_torch, y_train_torch)\n",
    "training_generator = DataLoader(training_set, batch_size=batch, shuffle=True)\n",
    "\n",
    "testing_set = MTDNNData(x_test_torch, y_test_torch)\n",
    "testing_generator = DataLoader(testing_set, batch_size=len(testing_set), shuffle=False)\n",
    "\n",
    "valid_set = MTDNNData(x_valid_torch, y_valid_torch)\n",
    "valid_generator = DataLoader(valid_set, batch_size=len(valid_set), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MTDNN(torch.nn.Module):\n",
    "    def __init__(self, input_shape, all_tasks):\n",
    "        super(MTDNN, self).__init__()\n",
    "\n",
    "        self.shared_1 = torch.nn.Linear(input_shape, 2048)\n",
    "        self.batchnorm_1 = torch.nn.BatchNorm1d(2048)\n",
    "        \n",
    "        self.shared_2 = torch.nn.Linear(2048, 1024)\n",
    "        self.batchnorm_2 = torch.nn.BatchNorm1d(1024)\n",
    "        \n",
    "        self.hidden_3 = torch.nn.ModuleList([torch.nn.Linear(1024, 512) for task in all_tasks])\n",
    "        self.batchnorm_3 = torch.nn.ModuleList([torch.nn.BatchNorm1d(512) for task in all_tasks])\n",
    "        \n",
    "        self.hidden_4 = torch.nn.ModuleList([torch.nn.Linear(512, 256) for task in all_tasks])\n",
    "        self.batchnorm_4 = torch.nn.ModuleList([torch.nn.BatchNorm1d(256) for task in all_tasks])\n",
    "        \n",
    "        self.output   = torch.nn.ModuleList([torch.nn.Linear(256, 1) for task in all_tasks])\n",
    "        \n",
    "        self.leakyReLU = torch.nn.LeakyReLU(0.05)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.shared_1(x)\n",
    "        x = self.batchnorm_1(x)\n",
    "        x = self.leakyReLU(x)\n",
    "        \n",
    "        x = self.shared_2(x)\n",
    "        x = self.batchnorm_2(x)\n",
    "        x = self.leakyReLU(x)\n",
    "        \n",
    "        x_task = [None for i in range(len(self.output))]\n",
    "        for task in range(len(self.output)):\n",
    "            x_task[task] = self.hidden_3[task](x)\n",
    "            x_task[task] = self.batchnorm_3[task](x_task[task])\n",
    "            x_task[task] = self.leakyReLU(x_task[task])\n",
    "            \n",
    "            x_task[task] = self.hidden_4[task](x_task[task])\n",
    "            x_task[task] = self.batchnorm_4[task](x_task[task])\n",
    "            x_task[task] = self.leakyReLU(x_task[task])\n",
    "            \n",
    "            x_task[task] = self.output[task](x_task[task])\n",
    "            x_task[task] = torch.sigmoid(x_task[task])\n",
    "        \n",
    "        y_pred = x_task\n",
    "        \n",
    "        return y_pred\n",
    "    \n",
    "model = MTDNN(input_shape, all_tasks).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_ckp(state, is_best, checkpoint_path, best_model_path):\n",
    "    # Method from : https://gist.github.com/vsay01/45dfced69687077be53dbdd4987b6b17\n",
    "    f_path = checkpoint_path\n",
    "    torch.save(state, f_path)\n",
    "    if is_best:\n",
    "        best_fpath = best_model_path\n",
    "        shutil.copyfile(f_path, best_fpath)\n",
    "        \n",
    "def load_ckp(checkpoint_fpath, input_model, optimizer):\n",
    "    checkpoint = torch.load(checkpoint_fpath)\n",
    "    input_model.load_state_dict(checkpoint['state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    train_loss_min = checkpoint['train_loss_min']\n",
    "    return model, optimizer, checkpoint['epoch'], train_loss_min.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = \"./checkpoints\"\n",
    "\n",
    "if not os.path.exists(ckpt_path):\n",
    "    os.mkdir(ckpt_path)\n",
    "\n",
    "checkpoint_file= ckpt_path + '/current_checkpoint.pt'\n",
    "bestmodel_file = ckpt_path + '/best_model.pt'  \n",
    "bestmodel_byvalid_file = ckpt_path + '/best_model_by_valid.pt' \n",
    "bestmodel_byvalid_crossed_file = ckpt_path + '/best_model_by_valid-crossed.pt'   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_history=[]  \n",
    "correct_history=[]  \n",
    "val_loss_history=[]  \n",
    "val_correct_history=[] \n",
    "train_loss_min = np.Inf\n",
    "val_loss_min = np.Inf\n",
    "\n",
    "for e in range(train_epoch):\n",
    "    \n",
    "    model.train()\n",
    "\n",
    "    running_train_loss = 0\n",
    "    running_valid_loss = 0\n",
    "    running_train_correct = 0\n",
    "    running_val_correct = 0\n",
    "    y_train_true = []\n",
    "    y_train_pred = []\n",
    "    y_valid_true = []\n",
    "    y_valid_pred = []\n",
    "    batch = 0\n",
    "    for x_batch, y_batch in training_generator:\n",
    "        batch += 1\n",
    "        if torch.cuda.is_available():\n",
    "            x_batch, y_batch = x_batch.cuda(), y_batch.cuda() \n",
    "        \n",
    "        y_pred = model(x_batch)\n",
    "        \n",
    "        # Compute loss over all tasks\n",
    "        loss = 0\n",
    "        correct = 0\n",
    "        y_train_true_task = []\n",
    "        y_train_pred_task = []\n",
    "        for i in range(len(all_tasks)):\n",
    "            y_batch_task = y_batch[:,i]\n",
    "            y_pred_task  = y_pred[i][:,0]\n",
    "            \n",
    "            indice_valid = y_batch_task >= 0\n",
    "            loss_task = criterion(y_pred_task[indice_valid], y_batch_task[indice_valid]) / N_train[i]\n",
    "            \n",
    "            loss += loss_task\n",
    "\n",
    "            pred_train = np.round(y_pred_task[indice_valid].detach().cpu().numpy())\n",
    "            target_train = y_batch_task[indice_valid].float()\n",
    "            y_train_true.extend(target_train.tolist()) \n",
    "            y_train_pred.extend(pred_train.reshape(-1).tolist())\n",
    "\n",
    "        writer.add_scalar(\"Accuracy/train\", loss, batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "        running_train_loss += loss.item()\n",
    "        writer.add_scalar(\"Loss/train\", running_train_loss, e)\n",
    "        \n",
    "    else:\n",
    "        with torch.no_grad():    \n",
    "        ## evaluation part \n",
    "            model.eval()\n",
    "            for val_x_batch, val_y_batch in valid_generator:\n",
    "                \n",
    "                if torch.cuda.is_available():\n",
    "                    val_x_batch, val_y_batch = val_x_batch.cuda(), val_y_batch.cuda() \n",
    "                \n",
    "                val_output = model(val_x_batch)\n",
    "\n",
    "                ## 2. loss calculation over all tasks \n",
    "                val_loss = 0\n",
    "                val_correct = 0\n",
    "                y_valid_true_task = []\n",
    "                y_valid_pred_task = []\n",
    "                for i in range(len(all_tasks)):\n",
    "                    val_y_batch_task = val_y_batch[:,i]\n",
    "                    val_output_task  = val_output[i][:,0]\n",
    "\n",
    "                    # compute loss for labels that are not NA\n",
    "                    indice_valid = val_y_batch_task >= 0\n",
    "                    val_loss_task = criterion(val_output_task[indice_valid], val_y_batch_task[indice_valid]) / N_valid[i]\n",
    "\n",
    "                    val_loss += val_loss_task\n",
    "                    \n",
    "                    pred_valid = np.round(val_output_task[indice_valid].detach().cpu().numpy())\n",
    "                    target_valid = val_y_batch_task[indice_valid].float()\n",
    "                    y_valid_true.extend(target_valid.tolist()) \n",
    "                    y_valid_pred.extend(pred_valid.reshape(-1).tolist())\n",
    "                \n",
    "\n",
    "                running_valid_loss+=val_loss.item()\n",
    "                writer.add_scalar(\"Loss/valid\", running_valid_loss, e)\n",
    "        \n",
    "        #epoch loss\n",
    "        train_epoch_loss=np.mean(running_train_loss)\n",
    "        val_epoch_loss=np.mean(running_valid_loss)  \n",
    "       \n",
    "        #epoch accuracy     \n",
    "        train_epoch_acc = accuracy_score(y_train_true,y_train_pred)\n",
    "        val_epoch_acc = accuracy_score(y_valid_true,y_valid_pred)\n",
    "        \n",
    "        #history\n",
    "        loss_history.append(train_epoch_loss)  \n",
    "        correct_history.append(train_epoch_acc)\n",
    "        val_loss_history.append(val_epoch_loss)  \n",
    "        val_correct_history.append(val_epoch_acc)  \n",
    "        \n",
    "        print(f\"Epoch: {e}, Training loss: {train_epoch_loss:.3f}, Valid loss: {val_epoch_loss:.3f}\")\n",
    "        print(f\"Training acc:{train_epoch_acc:.3f}, Valid acc: {val_epoch_acc:.3f}\")\n",
    "        \n",
    "        checkpoint = {\n",
    "            'epoch': e + 1,\n",
    "            'train_loss_min': train_epoch_loss,\n",
    "            'val_loss_min': val_epoch_loss, \n",
    "            'state_dict': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "        }\n",
    "        \n",
    "        save_ckp(checkpoint, False, checkpoint_file, bestmodel_file)\n",
    "        \n",
    "        if train_epoch_loss <= train_loss_min:\n",
    "            save_ckp(checkpoint, True, checkpoint_file, bestmodel_file)\n",
    "            train_loss_min = train_epoch_loss\n",
    "            \n",
    "        if train_epoch_loss >= val_epoch_loss:\n",
    "            save_ckp(checkpoint, True, checkpoint_file, bestmodel_byvalid_crossed_file)\n",
    "            train_loss_min = train_epoch_loss\n",
    "            \n",
    "        if val_epoch_loss <= val_loss_min:\n",
    "            save_ckp(checkpoint, True, checkpoint_file, bestmodel_file)\n",
    "            val_loss_min = val_epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model, optimizer, start_epoch, train_loss_min = load_ckp(bestmodel_byvalid, model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x_test_torch, y_test_torch in testing_generator:\n",
    "    y_test_pred = loaded_model.eval().to(device).cpu()(x_test_torch)\n",
    "    \n",
    "    loss = 0\n",
    "    for i in range(len(all_tasks)):\n",
    "        y_test_task = y_test_torch[:,i]\n",
    "        y_pred_task  = y_test_pred[i][:,0]\n",
    "\n",
    "        indice_valid = y_test_task >= 0\n",
    "        loss_task = criterion(y_pred_task[indice_valid], y_test_task[indice_valid]) / N_test[i]\n",
    "\n",
    "        loss += loss_task\n",
    "    \n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "\n",
    "for i in range(len(all_tasks)):\n",
    "    \n",
    "    valid_datapoints = y_test[:,i] >= 0\n",
    "    y_test_task = y_test[valid_datapoints,i] \n",
    "    y_test_pred_task = y_test_pred[i].detach().numpy()[valid_datapoints,0]\n",
    "    \n",
    "    acc = accuracy_score(y_test_task, np.round(y_test_pred_task))\n",
    "    print('Accuracy for MTDNN on Morgan Fingerprint:', acc)\n",
    "    \n",
    "    bacc = sk.metrics.balanced_accuracy_score(y_test_task, np.round(y_test_pred_task))\n",
    "\n",
    "    f1 = f1_score(y_test_task, np.round(y_test_pred_task), pos_label=1)\n",
    "    print('F1 for MTDNN on Morgan Fingerprint:', f1)\n",
    "\n",
    "    cfm = sk.metrics.confusion_matrix(y_test_task, np.round(y_test_pred_task))\n",
    "    cfm = cfm.astype('float') / cfm.sum(axis=1)[:, np.newaxis]\n",
    "    \n",
    "    tn, fp, fn, tp = cfm.ravel()\n",
    "    pr = tp / (tp + fp)\n",
    "    rc = tp / (tp + fn)\n",
    "    print(' True Positive:', tp)\n",
    "    print(' True Negative:', tn)\n",
    "    print('False Positive:', fp)\n",
    "    print('False Negative:', fn)\n",
    "    \n",
    "    \n",
    "    auc = roc_auc_score(y_test_task, y_test_pred_task)\n",
    "    print('Test ROC AUC ({}):'.format(all_tasks[i]), auc)\n",
    "    \n",
    "    results[all_tasks[i]] = [auc, acc, bacc, tn, tp, pr, rc, f1]\n",
    "\n",
    "    fpr, tpr, threshold = sk.metrics.roc_curve(y_test_task, y_test_pred_task)\n",
    "    plt.plot(fpr, tpr, 'b', label = 'AUC')\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Task'.ljust(10), '\\t', '  AUC ', ' ACC ', ' BACC ', ' TN  ', ' TP  ', ' PR  ', ' RC  ', ' F1  ')\n",
    "for task, auc in results.items():\n",
    "    print(task.ljust(10), '\\t', np.round(auc,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print test loss\n",
    "for x_valid_torch, y_valid_torch in valid_generator:\n",
    "    y_valid_pred = model.eval().to(device).cpu()(x_valid_torch)\n",
    "    \n",
    "    # Compute loss over all tasks\n",
    "    loss = 0\n",
    "    for i in range(len(all_tasks)):\n",
    "        y_test_task = y_valid_torch[:,i]\n",
    "        y_pred_task  = y_valid_pred[i][:,0]\n",
    "\n",
    "        # compute loss for labels that are not NA\n",
    "        indice_valid = y_test_task >= 0\n",
    "        loss_task = criterion(y_pred_task[indice_valid], y_test_task[indice_valid]) / N_test[i]\n",
    "\n",
    "        loss += loss_task\n",
    "    \n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_valid = {}\n",
    "# Collects performance metrics for all tasks on Valid set\n",
    "for i in range(len(all_tasks)):\n",
    "    \n",
    "    valid_datapoints = y_valid[:,i] >= 0\n",
    "    y_valid_task = y_valid[valid_datapoints,i] \n",
    "    y_valid_pred_task = y_valid_pred[i].detach().numpy()[valid_datapoints,0]\n",
    "    \n",
    "    \n",
    "    acc = accuracy_score(y_valid_task, np.round(y_valid_pred_task))\n",
    "    print('Accuracy for deepnn on Morgan Fingerprint:', acc)\n",
    "    \n",
    "    bacc = sk.metrics.balanced_accuracy_score(y_valid_task, np.round(y_valid_pred_task))\n",
    "\n",
    "    f1 = f1_score(y_valid_task, np.round(y_valid_pred_task), pos_label=1)\n",
    "    print('F1 for deepnn on Morgan Fingerprint:', f1)\n",
    "\n",
    "    cfm = sk.metrics.confusion_matrix(y_valid_task, np.round(y_valid_pred_task))\n",
    "    cfm = cfm.astype('float') / cfm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    print('Confusion Matrix for deepnn on Morgan Fingerprint:\\n', cfm)\n",
    "\n",
    "    tn, fp, fn, tp = cfm.ravel()\n",
    "    pr = tp / (tp + fp)\n",
    "    rc = tp / (tp + fn)\n",
    "    print(' True Positive:', tp)\n",
    "    print(' True Negative:', tn)\n",
    "    print('False Positive:', fp)\n",
    "    print('False Negative:', fn)\n",
    "    \n",
    "    \n",
    "    auc = roc_auc_score(y_valid_task, y_valid_pred_task)\n",
    "    print('Test ROC AUC ({}):'.format(all_tasks[i]), auc)\n",
    "    \n",
    "    results_valid[all_tasks[i]] = [auc, acc, bacc, tn, tp, pr, rc, f1]\n",
    "\n",
    "    fpr, tpr, threshold = sk.metrics.roc_curve(y_valid_task, y_valid_pred_task)\n",
    "    plt.plot(fpr, tpr, 'b', label = 'AUC')\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Task'.ljust(10), '\\t', '  AUC ', ' ACC ', ' BACC ', ' TN  ', ' TP  ', ' PR  ', ' RC  ', ' F1  ')\n",
    "for task, auc in results_valid.items():\n",
    "    print(task.ljust(10), '\\t', np.round(auc,3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
